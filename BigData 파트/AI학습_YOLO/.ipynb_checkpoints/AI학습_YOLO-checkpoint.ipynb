{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5be0be75-8664-4e03-9d5c-553dfa305316",
   "metadata": {},
   "source": [
    "# Object Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7768cb85-46ea-4468-bf56-9a23c69111b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "from time import time\n",
    "import sys\n",
    "\n",
    "\n",
    "class ObjectDetection:\n",
    "    \"\"\"\n",
    "    The class performs generic object detection on a video file.\n",
    "    It uses yolo5 pretrained model to make inferences and opencv2 to manage frames.\n",
    "    Included Features:\n",
    "    1. Reading and writing of video file using  Opencv2\n",
    "    2. Using pretrained model to make inferences on frames.\n",
    "    3. Use the inferences to plot boxes on objects along with labels.\n",
    "    Upcoming Features:\n",
    "    \"\"\"\n",
    "    def __init__(self, input_file, out_file=\"Labeled_Video.avi\"):\n",
    "        \"\"\"\n",
    "        :param input_file: provide youtube url which will act as input for the model.\n",
    "        :param out_file: name of a existing file, or a new file in which to write the output.\n",
    "        :return: void\n",
    "        \"\"\"\n",
    "        self.input_file = input_file\n",
    "        self.model = self.load_model()\n",
    "        self.model.conf = 0.4 # set inference threshold at 0.3\n",
    "        self.model.iou = 0.3 # set inference IOU threshold at 0.3\n",
    "        self.model.classes = [0] # set model to only detect \"Person\" class\n",
    "        self.out_file = out_file\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "    def get_video_from_file(self):\n",
    "        \"\"\"\n",
    "        Function creates a streaming object to read the video from the file frame by frame.\n",
    "        :param self:  class object\n",
    "        :return:  OpenCV object to stream video frame by frame.\n",
    "        \"\"\"\n",
    "        cap = cv2.VideoCapture(self.input_file)\n",
    "        assert cap is not None\n",
    "        return cap\n",
    "\n",
    "    def load_model(self):\n",
    "        \"\"\"\n",
    "        Function loads the yolo5 model from PyTorch Hub.\n",
    "        \"\"\"\n",
    "        model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\n",
    "        return model\n",
    "\n",
    "    def score_frame(self, frame):\n",
    "        \"\"\"\n",
    "        function scores each frame of the video and returns results.\n",
    "        :param frame: frame to be infered.\n",
    "        :return: labels and coordinates of objects found.\n",
    "        \"\"\"\n",
    "        self.model.to(self.device)\n",
    "        results = self.model([frame])\n",
    "        labels, cord = results.xyxyn[0][:, -1].to('cpu').numpy(), results.xyxyn[0][:, :-1].to('cpu').numpy()\n",
    "        return labels, cord\n",
    "\n",
    "    def plot_boxes(self, results, frame):\n",
    "        \"\"\"\n",
    "        plots boxes and labels on frame.\n",
    "        :param results: inferences made by model\n",
    "        :param frame: frame on which to  make the plots\n",
    "        :return: new frame with boxes and labels plotted.\n",
    "        \"\"\"\n",
    "        labels, cord = results\n",
    "        n = len(labels)\n",
    "        x_shape, y_shape = frame.shape[1], frame.shape[0]\n",
    "        for i in range(n):\n",
    "            row = cord[i]\n",
    "            x1, y1, x2, y2 = int(row[0]*x_shape), int(row[1]*y_shape), int(row[2]*x_shape), int(row[3]*y_shape)\n",
    "            bgr = (0, 0, 255)\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), bgr, 3)\n",
    "            label = f\"{int(row[4]*100)}\"\n",
    "            cv2.putText(frame, label, (x1, y1), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 1)\n",
    "            cv2.putText(frame, f\"Total Targets: {n}\", (30, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "        return frame\n",
    "\n",
    "    def __call__(self):\n",
    "        player = self.get_video_from_file() # create streaming service for application\n",
    "        assert player.isOpened()\n",
    "        x_shape = int(player.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        y_shape = int(player.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        four_cc = cv2.VideoWriter_fourcc(*\"MJPG\")\n",
    "        out = cv2.VideoWriter(self.out_file, four_cc, 20, (x_shape, y_shape))\n",
    "        fc = 0\n",
    "        fps = 0\n",
    "        tfc = int(player.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        tfcc = 0\n",
    "        while True:\n",
    "            fc += 1\n",
    "            start_time = time()\n",
    "            ret, frame = player.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            results = self.score_frame(frame)\n",
    "            frame = self.plot_boxes(results, frame)\n",
    "            end_time = time()\n",
    "            fps += 1/np.round(end_time - start_time, 3)\n",
    "            if fc == 10:\n",
    "                fps = int(fps / 10)\n",
    "                tfcc += fc\n",
    "                fc = 0\n",
    "                per_com = int(tfcc / tfc * 100)\n",
    "                print(f\"Frames Per Second : {fps} || Percentage Parsed : {per_com}\")\n",
    "            out.write(frame)\n",
    "        player.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b1b981-526b-4fdf-9544-233a4031cc6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "link = sys.argv[1]\n",
    "output_file = sys.argv[2]\n",
    "a = ObjectDetection(\"C:/Users/sunfo/Downloads/이상행동 CCTV 영상/02.싸움(fight)/insidedoor_03/37-4/37-4_cam01_fight01_place02_night_spring.mp4\", \n",
    "                   'C:/Users/sunfo/OneDrive/바탕 화면/detected_37-4_cam01_fight01_place02_night_spring.mp4')\n",
    "a()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2885bd-5e01-4a3a-acaa-9ffff77b830e",
   "metadata": {},
   "source": [
    "# Custom Training\n",
    "### test_size=0.5 / epochs 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ca16f2-c1f8-4af9-8ce3-ee7b095fae50",
   "metadata": {},
   "source": [
    "violence,NonViolence detection \n",
    "https://universe.roboflow.com/nuscrimesocietydatasets/violence-9gmjx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "627773fd-dc5b-4f58-87fb-6144246a1352",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-16T01:30:51.500908Z",
     "iopub.status.busy": "2023-01-16T01:30:51.500908Z",
     "iopub.status.idle": "2023-01-16T01:30:51.668196Z",
     "shell.execute_reply": "2023-01-16T01:30:51.666207Z",
     "shell.execute_reply.started": "2023-01-16T01:30:51.500908Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2999\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "\n",
    "img_list = glob('C:/sooeun/DATAexam/ConvergenceProject-CareSystem/roboflow/combined/images/*.jpg')\n",
    "print(len(img_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6298379e-b611-4ea3-a1cc-e140d1f07d17",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-16T01:30:52.690738Z",
     "iopub.status.busy": "2023-01-16T01:30:52.690738Z",
     "iopub.status.idle": "2023-01-16T01:30:52.704789Z",
     "shell.execute_reply": "2023-01-16T01:30:52.703786Z",
     "shell.execute_reply.started": "2023-01-16T01:30:52.690738Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ! pip install numpy --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f156dda2-72bb-4a52-a040-1d32aed65cb5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-16T01:30:53.660192Z",
     "iopub.status.busy": "2023-01-16T01:30:53.660192Z",
     "iopub.status.idle": "2023-01-16T01:30:55.668288Z",
     "shell.execute_reply": "2023-01-16T01:30:55.666291Z",
     "shell.execute_reply.started": "2023-01-16T01:30:53.660192Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ppi06\\anaconda3\\envs\\data_venv\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1499 1500\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_img_list, val_img_list = train_test_split(img_list, test_size=0.5, random_state=2000)\n",
    "print(len(train_img_list), len(val_img_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "113690cc-9e89-4b0c-943a-6ad4a65a725c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-16T01:30:55.670282Z",
     "iopub.status.busy": "2023-01-16T01:30:55.670282Z",
     "iopub.status.idle": "2023-01-16T01:30:55.685350Z",
     "shell.execute_reply": "2023-01-16T01:30:55.681790Z",
     "shell.execute_reply.started": "2023-01-16T01:30:55.670282Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_img_list = glob(\"C:/sooeun/DATAexam/ConvergenceProject-CareSystem/roboflow/train/images/*.jpg\")\n",
    "# val_img_list = glob(\"C:/sooeun/DATAexam/ConvergenceProject-CareSystem/roboflow/valid/images/*.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d7174e1-a2d9-4545-bf93-5879665441e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-16T01:30:58.077961Z",
     "iopub.status.busy": "2023-01-16T01:30:58.077961Z",
     "iopub.status.idle": "2023-01-16T01:30:58.088875Z",
     "shell.execute_reply": "2023-01-16T01:30:58.086907Z",
     "shell.execute_reply.started": "2023-01-16T01:30:58.077961Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# len(train_img_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f31822de-486a-42ec-a0ca-6d419ab2431f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-16T01:30:58.787072Z",
     "iopub.status.busy": "2023-01-16T01:30:58.786077Z",
     "iopub.status.idle": "2023-01-16T01:30:58.807055Z",
     "shell.execute_reply": "2023-01-16T01:30:58.806085Z",
     "shell.execute_reply.started": "2023-01-16T01:30:58.787072Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train, val 정보에 대한 txt 파일 생성\n",
    "with open('C:/sooeun/DATAexam/ConvergenceProject-CareSystem/roboflow/train.txt', 'w') as f:\n",
    "    f.write('\\n'.join(train_img_list) + '\\n')\n",
    "    \n",
    "with open('C:/sooeun/DATAexam/ConvergenceProject-CareSystem/roboflow/val.txt', 'w') as f:\n",
    "    f.write('\\n'.join(val_img_list) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34a4edb6-2140-4326-a33a-95baab80ce99",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-16T01:31:00.735752Z",
     "iopub.status.busy": "2023-01-16T01:31:00.733429Z",
     "iopub.status.idle": "2023-01-16T01:31:00.929972Z",
     "shell.execute_reply": "2023-01-16T01:31:00.925970Z",
     "shell.execute_reply.started": "2023-01-16T01:31:00.735752Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'names': ['NonViolence', 'Violence'], 'nc': 2, 'train': 'C:/sooeun/DATAexam/ConvergenceProject-CareSystem/roboflow/train.txt', 'val': 'C:/sooeun/DATAexam/ConvergenceProject-CareSystem/roboflow/val.txt'}\n",
      "{'names': ['NonViolence', 'Violence'], 'nc': 2, 'train': 'C:/sooeun/DATAexam/ConvergenceProject-CareSystem/roboflow/train.txt', 'val': 'C:/sooeun/DATAexam/ConvergenceProject-CareSystem/roboflow/val.txt'}\n"
     ]
    }
   ],
   "source": [
    "# yaml 파일 수정\n",
    "import yaml\n",
    "\n",
    "with open(\"C:/sooeun/DATAexam/ConvergenceProject-CareSystem/roboflow/data.yaml\", 'r') as f:\n",
    "    data = yaml.safe_load(f)\n",
    "    \n",
    "print(data)\n",
    "\n",
    "data['train'] = \"C:/sooeun/DATAexam/ConvergenceProject-CareSystem/roboflow/train.txt\"\n",
    "data['val'] = \"C:/sooeun/DATAexam/ConvergenceProject-CareSystem/roboflow/val.txt\"\n",
    "\n",
    "with open(\"C:/sooeun/DATAexam/ConvergenceProject-CareSystem/roboflow/data.yaml\", 'w') as f:\n",
    "    yaml.dump(data, f)\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96978fd9-aea4-4ecd-9562-9485924d4290",
   "metadata": {},
   "source": [
    "## ---여기서부터 기동---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2dc4ef3-c6b4-40e3-a185-75682be81177",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-16T01:31:03.815859Z",
     "iopub.status.busy": "2023-01-16T01:31:03.815859Z",
     "iopub.status.idle": "2023-01-16T01:31:03.824396Z",
     "shell.execute_reply": "2023-01-16T01:31:03.823393Z",
     "shell.execute_reply.started": "2023-01-16T01:31:03.815859Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "273237d7-5a58-46ff-9b55-c7528b28d3df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-16T01:31:04.961270Z",
     "iopub.status.busy": "2023-01-16T01:31:04.958278Z",
     "iopub.status.idle": "2023-01-16T01:33:45.128193Z",
     "shell.execute_reply": "2023-01-16T01:33:45.125188Z",
     "shell.execute_reply.started": "2023-01-16T01:31:04.960272Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ppi06\\yolov5\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "# yolo 경로로 이동\n",
    "# yolov5s로 training\n",
    "%cd C:\\Users\\ppi06\\yolov5\n",
    "!python train.py --img 416 --batch 16 --epochs 20 --data C:\\sooeun\\DATAexam\\ConvergenceProject-CareSystem\\roboflow\\data.yaml --cfg C:/Users/ppi06/yolov5/models/yolov5s.yaml --weights yolov5s.pt --name 230116_roboflow_dataset_test1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73faf78-754c-4821-881e-a7928e60515c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-15T03:05:36.993592Z",
     "iopub.status.busy": "2023-01-15T03:05:36.993592Z",
     "iopub.status.idle": "2023-01-15T03:05:38.592530Z",
     "shell.execute_reply": "2023-01-15T03:05:38.590531Z",
     "shell.execute_reply.started": "2023-01-15T03:05:36.993592Z"
    }
   },
   "source": [
    "### best.pt 경로 확인 후 변경 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c3c7a3-c2eb-4624-bef2-e6dbf67fd8dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 학습된 모델로 detecting\n",
    "!python detect.py --source C:/sooeun/DATAexam/ConvergenceProject-CareSystem/12-6_cam01_assault01_place09_day_summer.mp4 --weights C:/Users/ppi06/yolov5/runs/train/230116_roboflow_dataset_test12/weights/best.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9016925f-e2cb-4774-aa43-db7aaf8f6dfc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
